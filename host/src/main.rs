// These constants represent the RISC-V ELF and the image ID generated by risc0-build.
// The ELF is used for proving and the ID is used for verification.
mod host_metrics;
use host_metrics::HostMetrics;
use methods::{ GUEST_PROOFING_LOGIC_ELF, GUEST_PROOFING_LOGIC_ID };
use risc0_zkvm::{ default_prover, ExecutorEnv, Receipt, ReceiptKind };
use serde::{ Deserialize, Serialize };
use rdkafka::consumer::{ Consumer, StreamConsumer };
use rdkafka::producer::{ FutureProducer, FutureRecord };
use rdkafka::config::ClientConfig;
use tokio::time::Duration;
use rdkafka::message::Message;
use serde_json::json;
use log::info;
use serde_json::Value;
use ::std::collections::HashMap;
use proving_service_core::proofing_document::*;
use std::fs::File;
use std::io::Write;
use std::time::Instant;
use base64::{ engine::general_purpose, Engine as _ };
use std::sync::OnceLock;
use std::sync::atomic::{ AtomicUsize, Ordering };
use axum::{ routing::get, routing::post, Router, Json };

static GLOBAL_RUN_ID: OnceLock<AtomicUsize> = OnceLock::new();

#[derive(Serialize)]
#[allow(non_snake_case)]
struct ProofResponse {
    productFootprintId: String,
    proofReceipt: String,
    proofReference: String,
    pcf: f64,
    imageId: String,
}

/*
#[derive(Serialize, Deserialize)]
pub struct StoredData {
    pub receipt: Receipt,
    pub previous_id: [u32; 8],
}

#[derive(Deserialize, Serialize)]
struct ShipmentInfo {
    activity_data_json: String,
    activity_signature: String,
    activity_public_key_pem: String,
}

#[derive(Deserialize, Serialize)]
struct Shipment {
    shipment_id: String,
    info: ShipmentInfo,
}
*/

const TOPIC_IN: &str = "shipments";
const TOPIC_OUT: &str = "pcf-results";

async fn process_payload(payload_str: &str) -> Option<ProofResponse> {
    println!("Rohdaten der Nachricht: {}", payload_str);
    // Versuch direkt zu parsen (raw JSON)
    if let Ok(proof_response) = try_handle_raw_json(payload_str).await {
        return Some(proof_response);
    }

    // Falls das fehlschlägt, versuche es als stringifizierten JSON-String zu entpacken
    let inner_json_str: String = match serde_json::from_str(payload_str) {
        Ok(s) => s,
        Err(e) => {
            eprintln!("Fehler beim Entpacken des JSON-Strings: {}", e);
            return None;
        }
    };

    try_handle_raw_json(&inner_json_str).await.ok()
}

async fn try_handle_raw_json(shipments_json: &str) -> Result<ProofResponse, ()> {
    match handle_kafka_message(shipments_json).await {
        Some(resp) => Ok(resp),
        None => Err(()),
    }
}

#[tokio::main]
async fn main() {
    GLOBAL_RUN_ID.set(AtomicUsize::new(0)).expect("Failed to initialize GLOBAL_RUN_ID");
    let brokers = std::env::var("KAFKA_BROKER").unwrap_or_else(|_| "localhost:9092".to_string());
    env_logger::init();

    let consumer: StreamConsumer = ClientConfig::new()
        .set("bootstrap.servers", &brokers)
        .set("security.protocol", "PLAINTEXT")
        .set("group.id", "risc0-pcf-kafka-group")
        .set("auto.offset.reset", "earliest")
        .set("enable.auto.commit", "true")
        .set("auto.commit.interval.ms", "5000")
        .create()
        .expect("Consumer creation failed");

    consumer.subscribe(&[TOPIC_IN]).unwrap();

    let producer: FutureProducer = ClientConfig::new()
        .set("bootstrap.servers", &brokers)
        .set("security.protocol", "PLAINTEXT")
        .create()
        .expect("Producer creation failed");

    loop {
        match consumer.recv().await {
            Ok(message) => {
                match message.payload_view::<str>() {
                    Some(Ok(payload_str)) => {
                        if let Some(proof_response) = process_payload(payload_str).await {
                            let result_json = serde_json
                                ::to_string(&proof_response)
                                .expect("Failed to serialize proof_response");
                            //print!("{}", result_json);
                            let record = FutureRecord::to(TOPIC_OUT)
                                .payload(&result_json)
                                .key("some-key");
                            let _ = producer.send(record, Duration::from_secs(10)).await;
                        } else {
                            info!("Ungültige Nachricht wurde ignoriert.");
                        }
                    }
                    Some(Err(e)) => eprintln!("Payload UTF-8 error: {}", e),
                    None => eprintln!("No payload"),
                }
            }
            Err(e) => eprintln!("Kafka error receiving message: {:?}", e),
        }
    }
}

async fn handle_kafka_message(shipments_json: &str) -> Option<ProofResponse> {
    //println!("Rohdaten der Nachricht: {}", &shipments_json);

    let proofing_document: ProofingDocument = match serde_json::from_str(shipments_json) {
        Ok(s) => s,
        Err(e) => {
            eprintln!("Ungültige Nachricht ignoriert (JSON Fehler): {}", e);
            return None;
        }
    };
    println!("**{:#?}**", &proofing_document);
    let env = match
        ExecutorEnv::builder()
            .write(&proofing_document)
            .and_then(|b| b.build())
    {
        Ok(env) => env,
        Err(e) => {
            eprintln!("Fehler beim Erstellen der ExecutorEnv: {}", e);
            return None;
        }
    };

    let start_time = Instant::now(); // Starte die Zeitmessung

    let prover = default_prover();
    println!("ELF size: {}", GUEST_PROOFING_LOGIC_ELF.len());
    let prove_info = match prover.prove(env, GUEST_PROOFING_LOGIC_ELF) {
        Ok(info) => info,
        Err(e) => {
            eprintln!("Fehler beim Prove: {}", e);
            return None;
        }
    };
    let elapsed_time = start_time.elapsed(); // Beende die Zeitmessung
    let receipt = prove_info.receipt;

    let (journal_output, guest_metrics_from_journal): (f64, u64) = receipt.journal
        .decode()
        .unwrap();

    println!("RISC-V Zyklen (aus Guest): {}", guest_metrics_from_journal);

    // Host-Metriken initialisieren und befüllen
    let mut host_metrics = HostMetrics::new(
        "pcf_calculation_metrics.csv".to_string(), // Name der CSV-Datei
        get_next_run_id() // Eindeutige ID für diesen Lauf
    );

    host_metrics.runtime(elapsed_time.as_secs_f64());
    host_metrics.input_size(shipments_json.len() as u64);
    host_metrics.guest_cycles(guest_metrics_from_journal);
    host_metrics.proof_size(&receipt);

    // Metriken in CSV schreiben
    match host_metrics.metrics_write_csv() {
        Ok(_) => println!("Metriken erfolgreich in pcf_calculation_metrics.csv geschrieben."),
        Err(e) => eprintln!("Fehler beim Schreiben der Metriken: {}", e),
    }
    /*
    let journal_output: f64 = match receipt.journal.decode() {
        Ok(val) => val,
        Err(e) => {
            eprintln!("Fehler beim Dekodieren des Journals: {}", e);
            return None;
        }
    };
*/
    if let Err(e) = receipt.verify(GUEST_PROOFING_LOGIC_ID) {
        eprintln!("Receipt Verification failed: {}", e);
        return None;
    }

    let receipt_bytes = match bincode::serialize(&receipt) {
        Ok(bytes) => bytes,
        Err(e) => {
            eprintln!("Fehler beim Serialisieren des Receipts: {}", e);
            return None;
        }
    };

    let encoded_receipt = general_purpose::STANDARD.encode(receipt_bytes);

    println!("Journal output: {}", journal_output);

    println!("Handed over response ...");

    let proof_respone = ProofResponse {
        productFootprintId: proofing_document.productFootprint.id,
        proofReceipt: encoded_receipt,
        proofReference: "123".to_string(),
        pcf: journal_output,
        imageId: format!("{:?}", GUEST_PROOFING_LOGIC_ID),
    };
        let json_string = serde_json::to_string_pretty(&proof_respone).ok()?;
       let mut file = File::create("output.json").ok()?;
       file.write_all(&json_string.as_bytes()).ok()?;
    Some(proof_respone)
}

/*
async fn prove_plain_ad(Json(shipments): Json<Vec<Shipment>>) -> Json<ProofResponse> {
    // Initialize tracing (optional; remove if you initialize globally)
    let _ = tracing_subscriber::fmt()
        .with_env_filter(tracing_subscriber::EnvFilter::from_default_env())
        .try_init();

    let env = ExecutorEnv::builder()
        .write(&shipments)
        .unwrap()
        .build()
        .unwrap();

    let prover = default_prover();
    let prove_info = prover.prove(env, GUEST_PROOFING_LOGIC_ELF).unwrap();
    let receipt = prove_info.receipt;

    // Decode output from receipt journal
    let journal_output: f32 = receipt.journal.decode().unwrap();

    // Verify the receipt (optional here, but shows it works)
    receipt.verify(GUEST_PROOFING_LOGIC_ID).unwrap();

    // Serialize receipt (as base64-encoded bytes)
    let receipt_bytes = bincode::serialize(&receipt).unwrap();
    let encoded_receipt = general_purpose::STANDARD.encode(receipt_bytes);

    Json(ProofResponse {
        proof_receipt: encoded_receipt,
        journal_output,
        image_id: format!("{:?}", GUEST_PROOFING_LOGIC_ID),
    })
}
*/
fn get_next_run_id() -> String {
    // 1. Hole eine Referenz auf die AtomicUsize-Instanz
    let atomic_counter = GLOBAL_RUN_ID.get_or_init(|| AtomicUsize::new(0));

    // 2. Inkrementiere den Zähler atomar um 1
    //    `fetch_add(1, Ordering::SeqCst)`:
    //    - `fetch_add`: Führt eine atomare Addition durch.
    //    - `1`: Der Wert, um den inkrementiert werden soll.
    //    - `Ordering::SeqCst`: Das Memory Ordering. `SeqCst` (Sequential Consistency)
    //      ist die stärkste und sicherste Option für die meisten Anwendungsfälle.
    //
    //    WICHTIG: `fetch_add` gibt den *alten* Wert zurück, bevor die Addition erfolgt.
    //    Wenn du den *neuen* Wert nach der Inkrementierung haben möchtest, musst du 1 addieren.
    let old_value = atomic_counter.fetch_add(1, Ordering::SeqCst);
    let new_value = old_value + 1;

    // 3. Gib den neuen Wert als String zurück
    new_value.to_string()
}

#[cfg(test)]
mod tests {
    use super::handle_kafka_message;
    use crate::{ ProofResponse };
    use tokio;
    use std::fs;
    use std::sync::OnceLock;
    use std::sync::atomic::{ AtomicUsize, Ordering };

    #[tokio::test]
    async fn smoke_test_with_realistic_shipments_json() -> Result<(), Box<dyn std::error::Error>> {
        static GLOBAL_RUN_ID: OnceLock<AtomicUsize> = OnceLock::new();
        GLOBAL_RUN_ID.set(AtomicUsize::new(0)).expect("Failed to initialize GLOBAL_RUN_ID");
        let json_content = fs::read_to_string("src/shipment_1.json")?;

        // Call kafka handler
        let resp: ProofResponse = handle_kafka_message(&json_content).await.expect(
            "kafka_handler_failed"
        );

        Ok(())
    }
}
